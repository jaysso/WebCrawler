# Python WebCrawler
forked crawler code from https://github.com/Mondego/spacetime-crawler4py
### Designed to crawl the following URLs (domains) and paths:
##### --.ics.uci.edu/--
##### --.cs.uci.edu/--
##### --.informatics.uci.edu/--
##### --.stat.uci.edu/--
##### today.uci.edu/department/information_computer_sciences/--
###     AND the following:
##### - Honor the politeness delay for each site
##### - Crawl all pages with high textual information content
##### - Detect and avoid infinite traps
##### - Detect and avoid sets of similar pages with no information
##### - Detect and avoid dead URLs that return a 200 status but no data (click here to see what the different HTTP status codes mean (Links to an external site.))
##### - Detect and avoid crawling very large files, especially if they have low information value
